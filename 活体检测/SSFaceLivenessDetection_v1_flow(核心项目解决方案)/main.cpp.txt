#pragma once
/*
 Company:	Systhesis
 Author:	Yingpeng Chen
 Date :		2017-12-15
*/

#include <stdio.h>
#include <opencv2/opencv.hpp>
#include "facedetect-dll.h"
#include "CameraDS.h"
#include "flow.h"
#include "Liveness.h"
#include <fstream>
#include <sstream>
//#include <fiostream.h>
#include "SSLivenessDetection.h"
#include <time.h>

#pragma comment(lib,"libfacedetect.lib")
#pragma comment(lib,"SSLivenessDetection.lib")

using namespace cv;

//define the buffer size. Do not change the size!
#define DETECT_BUFFER_SIZE 0x20000

const int nor_width = 640;
const int nor_height = 480;
const int inf_width = 640;
const int inf_height = 480;

void liveness_detect(Liveness *live, IplImage* img, Rect faceRect, Mat &preGray, int *frameNumber, std::vector<float> &optFlowDiffArray, std::vector<float> &optLiveDiffArray, Mat &moveIdenImg)
{
	if (NULL == img)
		printf("Input frame data error!");
	
	if (faceRect.x < 0 || faceRect.y < 0 || faceRect.width <= 0 || faceRect.height <= 0)
		printf("Input face rect error!");

	//computer flow and live threshold value
	Mat frame, gray_frame, flow;
	frame = cv::Mat(img);
	cvtColor(frame, gray_frame, CV_BGR2GRAY);

	//int count = *frameNumber;

	optFlowDiffArray[(*frameNumber) % 20] = moveIdentificate(frame, faceRect, gray_frame, preGray, flow, (*frameNumber), moveIdenImg);
	optLiveDiffArray[(*frameNumber) % 20] = live->isLiveness(&IplImage(frame), faceRect.x, faceRect.y, faceRect.width);

	//std::cout << "flow threshold is " << optFlowDiffArray[(*frameNumber) % 20] << std::endl;
	//std::cout << "codebook threshold is " << optLiveDiffArray[(*frameNumber) % 20] << std::endl;
	std::cout << "Frame number is " << (*frameNumber) << std::endl;
}


//反视频欺骗的活体检测算法
DWORD WINAPI thread_liveness_detect(LPVOID p)
{
	CCameraDS * camera = (CCameraDS*)p;
	IplImage *img = cvCreateImage(cvSize(inf_width, inf_height), 8, 3);

	int * pResults = NULL;
	//pBuffer is used in the detection functions.
	//If you call functions in multiple threads, please create one buffer for each thread!
	unsigned char * pBuffer = (unsigned char *)malloc(DETECT_BUFFER_SIZE);
	if (!pBuffer)
	{
		fprintf(stderr, "Can not alloc inf camera buffer.\n");
		return -1;
	}
	int doLandmark = 1;

	//query frame
	Mat frame,gray_frame;
	Mat result_multiview_reinforce;

	//liveness detect
	Liveness liveness(inf_width, inf_height, 3);
	std::vector<float> liveDiffArray(20, 0.0);
	//detect flow
	Mat prev_gray_frame;
	int optFlowPicNumber = 0;
	std::vector<float> optFlowDiffArray(20, 0.0);
	Mat moveIdenInfImg;

	//SSLivenessHandle handle;
	//SS_LivenessSDK_Init(inf_width, inf_height, &handle);
	//FrameInfo info;


	//print log file
	int liveNumber = 0;
	int nonLiveNumber = 0;
    std::ofstream out("out.txt");

	clock_t start, finish;
	double totaltime;

	std::vector<cv::Point2f> landmarks;
	

	while (true)
	{
		if (camera->QueryFrame((unsigned char*)img->imageData))
		{
			start = clock();
			//face detection
			cvFlip(img);
			frame = cv::Mat(img);
			cvtColor(frame, gray_frame, CV_BGR2GRAY);
	
			pResults = facedetect_multiview_reinforce(pBuffer, (unsigned char*)(gray_frame.ptr(0)), gray_frame.cols, gray_frame.rows, (int)gray_frame.step,
				1.2f, 3, 48, 0, doLandmark);

			printf("%d faces detected.\n", (pResults ? *pResults : 0));

			result_multiview_reinforce = frame.clone();
			//print the detection results
			int x, y, w, h, neighbors, angle;
			for (int i = 0; i < (pResults ? *pResults : 0); i++)
			{
				short * p = ((short*)(pResults + 1)) + 142 * i;
				x = p[0];
				y = p[1];
				w = p[2];
				h = p[3];
				neighbors = p[4];
				angle = p[5];

				//printf("face_rect=[%d, %d, %d, %d], neighbors=%d, angle=%d\n", x, y, w, h, neighbors, angle);
				
				if (doLandmark)
				{
					for (int j = 36; j < 42; j++)//原来是68，眼睛（36-48）和嘴巴（48-68）
					{
						landmarks.push_back(Point((int)p[6 + 2 * j], (int)p[6 + 2 * j + 1]));
						cout << "x=" << x << ",y=" << y << endl;
						circle(result_multiview_reinforce, Point((int)p[6 + 2 * j], (int)p[6 + 2 * j + 1]), 1, Scalar(0, 255, 0));
						//cout << "x=" << x << ",y=" << y << endl;
					}		
				}
				int eye_rect_width = 0;
				int eye_rect_height = 0;
				int x_min_temp = 100000;
				int x_max_temp = 0;
				int y_min_temp = 10000;
				int y_max_temp = 0;
				for (int i = 0; i < landmarks.size(); ++i)
				{
					if (landmarks[i].x < x_min_temp)
						x_min_temp = landmarks[i].x;
					if (landmarks[i].x > x_max_temp)
						x_max_temp = landmarks[i].x;

					if (landmarks[i].y < y_min_temp)
						y_min_temp = landmarks[i].y;
					if (landmarks[i].y > y_max_temp)
						y_max_temp = landmarks[i].y;		
				}
				landmarks.clear();
				eye_rect_width = x_max_temp - x_min_temp;
				eye_rect_height = y_max_temp - y_min_temp;
				Rect left_eye_rect;
				left_eye_rect.x = x_min_temp;
				left_eye_rect.y = y_min_temp;
				left_eye_rect.width = eye_rect_width;
				left_eye_rect.height = eye_rect_height;

				//Mat left_eye;  画左眼
				Mat left_eye = frame(Rect(left_eye_rect.x, left_eye_rect.y, left_eye_rect.width, left_eye_rect.height));

				//声明一个三通道图像，像素值全为0，用来将霍夫变换检测出的圆画在上面  
				Mat dst(left_eye.size(), left_eye.type());
				dst = Scalar::all(0);
				
				Mat src_gray;//彩色图像转化成灰度图  
				cvtColor(left_eye, src_gray, COLOR_BGR2GRAY);
				imshow("原图-灰度", src_gray);
				imwrite("src_gray.png", src_gray);
				
				Mat bf;//对灰度图像进行双边滤波  
				 bilateralFilter(src_gray, bf, 15, 15 * 2, 15 / 2);
				imshow("灰度双边滤波处理", bf);
				imwrite("src_bf.png", bf);
				
				vector<Vec3f> circles;//声明一个向量，保存检测出的圆的圆心坐标和半径  
				HoughCircles(bf, circles, CV_HOUGH_GRADIENT, 1.5, 20, 130, 38, 10, 50);//霍夫变换检测圆  
				
				cout << "x=\ty=\tr=" << endl;
				for (size_t i = 0; i < circles.size(); i++)//把霍夫变换检测出的圆画出来  
				{
					Point center(cvRound(circles[i][0]), cvRound(circles[i][1]));
					int radius = cvRound(circles[i][2]);
					
					circle(dst, center, 0, Scalar(0, 255, 0), -1, 8, 0);
					circle(dst, center, radius, Scalar(0, 0, 255), 1, 8, 0);
					
					cout << cvRound(circles[i][0]) << "\t" << cvRound(circles[i][1]) << "\t"
					<< cvRound(circles[i][2]) << endl;//在控制台输出圆心坐标和半径                
				}
				
				imshow("left_eye", left_eye);
				cvWaitKey(1);
				
				Rect faceRect;
				faceRect.x = x;
				faceRect.y = y;
				faceRect.width = w;
				faceRect.height = h;

				//STEP1:光流
				Mat flow;
				//computer flow value
				optFlowDiffArray[optFlowPicNumber % 20] = moveIdentificate(frame, left_eye_rect, gray_frame, prev_gray_frame, flow, optFlowPicNumber, moveIdenInfImg);
				liveDiffArray[optFlowPicNumber % 20] = liveness.isLiveness(img, x, y, w);

				//out << "flow diff value: " << optFlowDiffArray[optFlowPicNumber % 20] << std::endl;
				//out << "border diff value: " << liveDiffArray[optFlowPicNumber % 20] << std::endl;
				std::cout << "flow threshold = " << optFlowDiffArray[optFlowPicNumber % 20] << std::endl;
				//std::cout << "codebook threshold = " << liveDiffArray[optFlowPicNumber % 20] << std::endl;
				std::cout << "Frame number is " << optFlowPicNumber << std::endl;
				//cout << "x=" << x << ",y=" << y << endl;
				//每次活检之前需
				if (optFlowPicNumber >= 30 && optFlowPicNumber % 20 == 0)
				{
					//compute sum flow diff
					float sumFlowDif = 0;
					for (auto iter = optFlowDiffArray.begin(); iter != optFlowDiffArray.end(); iter++)
					{
						sumFlowDif += *iter;
					}
					std::cout << "Value of Move Identification: " << sumFlowDif << std::endl;
					
					//compute sum live diff
					float sumLiveDiff = 0;
					for (auto iter = liveDiffArray.begin(); iter != liveDiffArray.end(); iter++)
					{
						sumLiveDiff += *iter;
					}
					//std::cout << "Value of Liveness Detection: " << sumLiveDiff << std::endl;

					if (sumFlowDif >0 && sumFlowDif <= 15 && liveDiffArray[optFlowPicNumber % 20] <= 0.1)
					{
						liveNumber++;
						std::cout << "This is Liveness!" << std::endl;

						rectangle(result_multiview_reinforce, Rect(x, y, w, h), Scalar(0, 255, 0), 2);
					}
					else
					{
						nonLiveNumber++;
						std::cout << "This is not Liveness!" << std::endl;
						rectangle(result_multiview_reinforce, Rect(x, y, w, h), Scalar(0, 0, 255), 2);
					}

					//print liveness detection result
					if (out.is_open())
					{
						out << "Value of Move Identification: " << sumFlowDif << std::endl;
						//out << "Value of Liveness Detection: " << sumLiveDiff << std::endl;

						if (sumFlowDif > 0 && sumFlowDif <= 15 && liveDiffArray[optFlowPicNumber % 20] <= 0.1)
							out << "This is Liveness!" << std::endl;
						else
							out << "This is not Liveness!" << std::endl;
					}
					optFlowPicNumber = 0;
					
				}

				
			}
			
			cv::imshow("InfCameraWindow", result_multiview_reinforce);

			if (cvWaitKey(20) == 'q')
				break;
		}
	}
	out << "Live number is " << liveNumber << std::endl;
	out << "Non live number is " << nonLiveNumber << std::endl;
	
	out.close();
	//release the buffer
	free(pBuffer);
	cvReleaseImage(&img);
	//SS_LivenessSDK_UnInit(handle);

	return 0;
}




//反照片欺骗的活体检测算法

void test()
{
	//open dual camera
	//CCameraDS *norCamera = new CCameraDS();		//正常摄像头
	CCameraDS *infCamera = new CCameraDS();		//红外摄像头

	//IplImage* infImage = cvCreateImage(cvSize(inf_width, inf_height), 8, 3);

	//int norNum = norCamera->FindVidOfCamera("vid_261a&pid_0016");
	//if (norNum >= 0)
	//{
	//	// 打开正常摄像头
	//	if (norCamera->OpenCamera(norNum, false, nor_width, nor_height))
	//	{
	//	}
	//}


	int infNum = infCamera->FindVidOfCamera("vid_261a&pid_0016");
	if (infNum >= 0)
	{
		//打开红外摄像头
		if (infCamera->OpenCamera(infNum, false, inf_width, inf_height))
		{

			HANDLE hThread = CreateThread(NULL, 0, thread_liveness_detect, (void*)infCamera, 0, NULL);
			Sleep(1000000);
			CloseHandle(hThread);
		}
	}

	//release the buffer
	//cvReleaseImage(&infImage);
	if (NULL != infCamera)
	{
		delete infCamera;
		infCamera = NULL;
	}

}


//void test1()
//{
//	char ImagePathName1[100] = "F:\\test\\0-2.jpg";
//	char ImagePathName2[100] = "F:\\test\\0-2.jpg";
//
//	int lpSize1 = 0, lpSize2 = 0, score = 0;
//	int iReturn = 0;
//
//	sprintf(ImagePathName1, "F:\\test\\0-2.jpg");
//	sprintf(ImagePathName2, "F:\\test\\0-2.jpg");
////	iReturn = AnalyzeFromFile(ImagePathName1, lpFeature1, &lpSize1);
////	if (iReturn != 0)
////	{
////		printf("从BMP文件中读取图像1失败\n");
////	}
////
////	iReturn = AnalyzeFromFile(ImagePathName2, lpFeature2, &lpSize2);
////	if (iReturn != 0)
////	{
////		printf("从BMP文件中读取图像2失败\n");
////	}
////
////	PatternMatch(lpFeature1, lpFeature2, &score);//对指纹进行比对
////
//	if (score >35)//原来是60
//	{
//		printf("Same!   \n");
//	}
//	else
//	{
//		printf("Different!  \n");
//	}
//	
//	IplImage *img = cvCreateImage(cvSize(inf_width, inf_height), 8, 3);
//
//	int * pResults = NULL;
//	
//	unsigned char * pBuffer = (unsigned char *)malloc(DETECT_BUFFER_SIZE);
//	if (!pBuffer)
//	{
//		fprintf(stderr, "Can not alloc inf camera buffer.\n");
//	}
//	int doLandmark = 1;
//
//	//query frame
//	Mat frame, gray_frame;
//	Mat result_multiview_reinforce;
//
//	
//
//		cvFlip(img);
//		frame = cv::Mat(img);
//		cvtColor(frame, gray_frame, CV_BGR2GRAY);
//
//		pResults = facedetect_multiview_reinforce(pBuffer, (unsigned char*)(gray_frame.ptr(0)), gray_frame.cols, gray_frame.rows, (int)gray_frame.step,
//			1.2f, 3, 48, 0, doLandmark);
//
//		printf("%d faces detected.\n", (pResults ? *pResults : 0));
//
//		result_multiview_reinforce = frame.clone();
//		//print the detection results
//		int x, y, w, h, neighbors, angle;
//		for (int i = 0; i < (pResults ? *pResults : 0); i++)
//		{
//			short * p = ((short*)(pResults + 1)) + 142 * i;
//			x = p[0];
//			y = p[1];
//			w = p[2];
//			h = p[3];
//			neighbors = p[4];
//			angle = p[5];
//
//			//printf("face_rect=[%d, %d, %d, %d], neighbors=%d, angle=%d\n", x, y, w, h, neighbors, angle);
//
//			if (doLandmark)
//			{
//				for (int j = 36; j < 48; j++)//原来是68，眼睛（36-48）和嘴巴（48-68）
//				{
//					landmarks.push_back(Point((int)p[6 + 2 * j], (int)p[6 + 2 * j + 1]));
//					circle(result_multiview_reinforce, Point((int)p[6 + 2 * j], (int)p[6 + 2 * j + 1]), 1, Scalar(0, 255, 0));
//
//				}
//			}
//
//			Rect faceRect;
//			faceRect.x = x;
//			faceRect.y = y;
//			faceRect.width = w;
//			faceRect.height = h;
//
//
//			//liveness_detect(&liveness, img, faceRect, prev_gray_frame, &optFlowPicNumber, optFlowDiffArray, liveDiffArray, moveIdenInfImg);
//			//STEP1:光流
//			Mat flow;
//			//computer flow value
//			optFlowDiffArray[optFlowPicNumber % 20] = moveIdentificate(frame, faceRect, gray_frame, prev_gray_frame, flow, optFlowPicNumber, moveIdenInfImg);
//			liveDiffArray[optFlowPicNumber % 20] = liveness.isLiveness(img, x, y, w);
//
//			
//
//			cout << "x=" << x << ",y=" << y << endl;
//	
//		cv::imshow("InfCameraWindow", result_multiview_reinforce);
//
//		
//	
//	out << "Live number is " << liveNumber << std::endl;
//	out << "Non live number is " << nonLiveNumber << std::endl;
//	out.close();
//	//release the buffer
//	free(pBuffer);
//	cvReleaseImage(&img);
//	//SS_LivenessSDK_UnInit(handle);
//
//	
//}

int main(int argc, char* argv[])
{
	test();

	return 0;
}


/*#include "opencv2\core\core.hpp"
#include "opencv2\imgproc\imgproc.hpp" 
#include "opencv2\highgui\highgui.hpp" 
//#include "opencv2/core/utility.hpp" 
#include "opencv2/video/tracking.hpp"
#include <iostream>
using namespace cv;
using namespace std;


template <typename Vec, typename Operator>
void foreach(Vec &v, Operator &op, size_t off, size_t len) {
	for (size_t i = off; i<len; ++i) {
		op(i, v[i]);
	}
}

template <typename Vec, typename Operator>
void foreach(Vec &v, Operator &op) {
	return foreach(v, op, 0, v.size());
}


void Abs(int i, float &it)
{
	it = abs(it);
}

//struct Copy
//{
//    vector<float> &v;
//    Copy(vector<float> & v) : v(v) {}
//    void operator () (float it)
//    {
//        v.push_back(it);
//    }
//};

struct MinMaxId
{
	float m, M;
	int mi, Mi;
	MinMaxId() : m(99999), M(-99999), mi(0), Mi(0) {}
	void operator () (int i, float & it)
	{
		if (it > M) { Mi = i;  M = it; }
		if (it < m) { mi = i;  m = it; }
	}
};


inline double hamming(double n, int N)
{
	return 0.54 - 0.46*cos((2.0*CV_PI*n) / (N - 1));
}
struct Hamming
{
	int N;
	Hamming(int n) : N(n) {}
	void operator () (int i, float & it)
	{
		it = it * float(hamming(i, N));
	}
};
struct HammingInv
{
	int N;
	HammingInv(int n) : N(n) {}
	void operator () (int i, float & it)
	{
		it = it / float(hamming(i, N));
	}
};


struct Ring
{
	vector<float> elm;
	vector<int64> tim;
	int p;

	Ring(int n = 1) : elm(n, 0), tim(n, 0), p(0)  {}

	void push(int64 t, float v)
	{
		p += 1;
		p %= elm.size();

		elm[p] = v;
		tim[p] = t;
	}

	// our timebuffer got sampled, whenever there was a frame available.
	// upsample to len samples evenly spaced in time 
	int wrap(vector<float> & din, size_t len = 512, float ts = 0.02f)
	{
		int   e = (p + 1) % elm.size();
		float t = float(tim[e] / getTickFrequency());
		float tz = float(tim[p] / getTickFrequency());
		while (din.size()<len && t<tz)
		{
			int  nxt = (e + 1) % elm.size();
			float t0 = float(tim[e] / getTickFrequency());
			float t1 = float(tim[nxt] / getTickFrequency());
			float v0 = elm[e];
			float v1 = elm[nxt];
			float v = float(v0 + (t - t0)*(v1 - v0) / (t1 - t0)); // lerp
			din.push_back(v);

			t += ts;
			if (t >= t1)
			{
				e = nxt;
			}
		}
		return p - e;
	}
};

void paint(Mat & img, const vector<float> & elm, int x, int y, Scalar col, float sy = 1.0f, float sx = 1.0f)
{
	size_t len = std::min(elm.size(), size_t(img.cols));
	for (size_t i = 1; i<len; i++)
	{
		line(img, Point(x + int(sx*(i - 1)), y + int(sy*elm[i - 1])), Point(x + int(sx*(i)), y + int(sy*elm[i])), col, 1);
	}
}

float bin2bpm(int b, float ts = 0.02f)
{
	return (60.0f * b) / (2.0f * 512.0f * ts);
}

void ontrack(int t, void *p)
{
	KalmanFilter * kf = (KalmanFilter*)p;
	double v = 1.0f / t;
	setIdentity(kf->processNoiseCov, Scalar::all(v));
	setIdentity(kf->measurementNoiseCov, Scalar::all(v));
	//kf->init(2,1);
}

int main(int argc, char** argv)
{
	bool doDct = true;
	bool doHam = true;
	bool doAbs = true;
	bool doKal = true;

	int hind = 2;
	int tpos = 15;
	int twid = 14;
	int kali = 1000;
	int spike_thresh = 30;

	Ring ring(256);
	Ring orig(256);
	Ring peak(128);
	Rect region = Rect(130, 100, 60, 60);
	Rect region_2 = Rect(440, 100, 60, 60);

	KalmanFilter KF(2, 1, 0);
	Mat measurement = Mat::zeros(1, 1, CV_32F);
	setIdentity(KF.measurementMatrix);
	setIdentity(KF.processNoiseCov, Scalar::all(.0001));
	setIdentity(KF.measurementNoiseCov, Scalar::all(0.0002));
	setIdentity(KF.errorCovPost, Scalar::all(1));

	namedWindow("cam", 0);
	namedWindow("control", 0);
	createTrackbar("pos", "control", &tpos, 512 - 128);
	createTrackbar("width", "control", &twid, 128);
	createTrackbar("kali", "control", &kali, 90000, ontrack, &KF);

	VideoCapture cap(0);
	int f = 0;
	int64 t = 0;
	while (cap.isOpened())
	{
		int64 t0 = getTickCount();
		Mat frame;
		cap >> frame;
		if (frame.empty())
			break;
		Mat draw = frame.clone();

		// take the diff of a skin to a non-skin rect as measure for change
		Mat roi1 = frame(region);
		Mat roi2 = frame(region_2);

		imshow("roi1", roi1);
		imshow("roi2", roi2);
		//Mat roi1; cvtColor(frame(region),roi1,COLOR_BGR2YCrCb);
		//Mat roi2; cvtColor(frame(region_2),roi2,COLOR_BGR2YCrCb);
		//roi1.copyTo(draw(region));
		Scalar m = mean(roi1);
		Scalar m2 = mean(roi2);
		float z = float(m[hind] - m2[hind]);
		//orig.push(t0,z);
		//if ( doKal )
		//{
		//    Mat predicted = KF.predict();
		//    measurement.at<float>(0) = z;
		//    KF.correct(measurement);
		//    z = predicted.at<float>(0);
		//}
		ring.push(t0, z);

		rectangle(draw, region, Scalar(200, 0, 0));
		line(draw, region.tl(), Point(region.tl().x, region.tl().y + int(m[0] / 4)), Scalar(150, 170, 0), 5);
		rectangle(draw, region_2, Scalar(20, 80, 10));
		line(draw, region_2.tl(), Point(region_2.tl().x, region_2.tl().y + int(m2[0] / 4)), Scalar(150, 170, 0), 5);

		int disiz = 0, dosiz = 0, Mi = 0;
		float pf = 1.0f;
		while (doDct && ring.elm.back() != 0) // once
		{
			pf = 3.0f;
			// skip dft if input contains spikes
			MinMaxId mm;
			foreach(ring.elm, mm);
			if (mm.M - mm.m > spike_thresh)
				break;

			vector<float> din, dout;
			int left = ring.wrap(din);
			disiz = ring.elm.size() - left;
			dosiz = din.size();
			if (doHam)
				foreach(din, Hamming(din.size()));

			dft(din, dout);

			if (doAbs)
				foreach(dout, Abs);
			paint(draw, dout, 50, 250, Scalar(0, 0, 200), 1.f, 4.f);
			rectangle(draw, Point(50 + tpos * 4, 250 - 30), Point(50 + (tpos + twid) * 4, 250 + 30), Scalar(200, 0, 0));

			// process the selected fft window:
			vector<float> clipped;
			clipped.insert(clipped.begin(), dout.begin() + tpos, dout.begin() + tpos + twid);

			// peak of fft is the actual cardiac
			MinMaxId mm3;
			foreach(clipped, mm3);

			vector<float> idft;
			dft(clipped, idft, DFT_INVERSE);

			if (doHam)
				foreach(idft, Hamming(idft.size()));
			paint(draw, idft, 50 + tpos, 250 - 30, Scalar(0, 220, 220), 0.8f, 5.0f);

			//// peak of ifft is the actual cardiac ?
			//MinMaxId mm3;
			//foreach(idft,mm3);

			float z = mm3.M;
			orig.push(t0, z);
			if (doKal)
			{
				Mat predicted = KF.predict();
				measurement.at<float>(0) = z;
				KF.correct(measurement);
				z = predicted.at<float>(0);
				paint(draw, orig.elm, 50, 350, Scalar(40, 40, 40), 3, 4);
			}

			peak.push(t0, z);
			//peak.push(mm3.Mi,mm3.M);
			paint(draw, peak.elm, 50, 350, Scalar(20, 140, 140), 3, 4);
			//vector<float> tim;
			//std::for_each(peak.tim.begin(),peak.tim.end(),Copy(tim));
			//paint(draw,tim,50,420,Scalar(20,20,60),1,4);
			circle(draw, Point(50 + peak.p * 4, 350 + int(peak.elm[peak.p]) * 3), 3, Scalar(60, 0, 230), 2);
			Mi = mm3.Mi + tpos;

			break;
		}
		paint(draw, ring.elm, 50, 50 - int(z), Scalar((hind == 0 ? 200 : 0), (hind == 1 ? 200 : 0), (hind == 2 ? 200 : 0)), pf);
		circle(draw, Point(50 + ring.p, 50 - int(z) + int(pf*ring.elm[ring.p])), 3, Scalar(60, 230, 0), 2);
		imshow("cam", draw);
		int k = waitKey(1);
		if (k == 27) break;
		if (k == '1') doDct = !doDct;
		if (k == '2') doHam = !doHam;
		if (k == '3') doAbs = !doAbs;
		if (k == '4') { hind++; hind %= 3; cerr << "hind " << hind << endl; }
		if (k == '5') doKal = !doKal;
		int64 t1 = getTickCount();
		t += (t1 - t0);
		if (f % 10 == 9)
		{
			double fps = 1.0 / double((t / 10) / getTickFrequency());
			cerr << format("%4d %3.3f %3.3f %6d %6d %3.3f", f, fps, z, disiz, dosiz, bin2bpm(Mi)) << endl;
			t = 0;
		}
		f++;
	}
	return 0;
}*/
